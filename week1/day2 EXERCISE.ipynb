{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as articles, blog posts, social media posts, and even entire books. This reduces the need for human writers and editors, saving time and resources.\n",
      "2. **Marketing Automation**: Generative AI can create personalized marketing materials, such as emails, advertisements, and product descriptions, based on customer data and preferences.\n",
      "3. **Product Design**: Generative AI can design products, such as furniture, clothing, and electronics, using parametric modeling and 3D printing. This enables fast prototyping and customization.\n",
      "4. **Customer Service**: Generative AI-powered chatbots can provide 24/7 customer support, answering frequently asked questions and routing complex issues to human representatives.\n",
      "5. **Data Analysis**: Generative AI can analyze large datasets and identify patterns, trends, and insights that may not be apparent through traditional methods.\n",
      "6. **Predictive Maintenance**: Generative AI can predict equipment failures and schedule maintenance, reducing downtime and increasing overall efficiency.\n",
      "7. **Supply Chain Optimization**: Generative AI can optimize supply chain operations by predicting demand, identifying bottlenecks, and suggesting alternative routes.\n",
      "8. **Financial Analysis**: Generative AI can analyze financial data and identify investment opportunities, predict stock prices, and generate trading strategies.\n",
      "9. **Language Translation**: Generative AI can translate languages in real-time, enabling faster communication across language barriers.\n",
      "10. **Creative Collaboration**: Generative AI can collaborate with human artists, writers, and designers to generate new ideas and concepts.\n",
      "\n",
      "Industry-specific applications:\n",
      "\n",
      "1. **Healthcare**: Generative AI can analyze medical images, identify patterns, and predict patient outcomes.\n",
      "2. **Education**: Generative AI can create personalized learning materials, adaptive assessments, and intelligent tutoring systems.\n",
      "3. **Retail**: Generative AI can design virtual store experiences, generate product recommendations, and optimize inventory management.\n",
      "4. **Manufacturing**: Generative AI can optimize production workflows, predict equipment failures, and suggest maintenance schedules.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Automate content creation, such as:\n",
      "\t* Writing articles, blog posts, and social media content.\n",
      "\t* Generating product descriptions, reviews, and testimonials.\n",
      "\t* Creating videos, images, and graphics.\n",
      "2. **Marketing Automation**: Use generative AI to:\n",
      "\t* Personalize marketing campaigns with customized messages and offers.\n",
      "\t* Automate email marketing and lead nurturing.\n",
      "\t* Create targeted social media ads and influencer partnerships.\n",
      "3. **Product Design and Development**: Leverage generative AI for:\n",
      "\t* Designing new products, such as furniture, electronics, or fashion items.\n",
      "\t* Creating prototypes and testing concepts.\n",
      "\t* Optimizing product features and performance.\n",
      "4. **Customer Service and Support**: Implement generative AI-powered chatbots to:\n",
      "\t* Provide 24/7 customer support and answer frequently asked questions.\n",
      "\t* Help customers with simple queries and issues.\n",
      "\t* Route complex issues to human customer support agents.\n",
      "5. **Data Analysis and Insights**: Use generative AI to:\n",
      "\t* Analyze large datasets and identify patterns, trends, and correlations.\n",
      "\t* Generate predictive models for demand forecasting, risk assessment, and market analysis.\n",
      "\t* Develop sentiment analysis tools to understand customer emotions and opinions.\n",
      "6. **Financial Modeling and Forecasting**: Automate financial modeling and forecasting using generative AI, including:\n",
      "\t* Predicting stock prices and market trends.\n",
      "\t* Generating financial forecasts and scenario planning.\n",
      "\t* Optimizing investment portfolios and risk management strategies.\n",
      "7. **Supply Chain Optimization**: Use generative AI to:\n",
      "\t* Analyze supply chain data and identify bottlenecks.\n",
      "\t* Generate optimized production schedules and inventory levels.\n",
      "\t* Predict demand fluctuations and adjust supply chain operations accordingly.\n",
      "8. **Creative Writing and Storytelling**: Leverage generative AI for:\n",
      "\t* Generating novel ideas, scripts, or stories.\n",
      "\t* Creating interactive narratives and immersive experiences.\n",
      "\t* Developing chatbots and virtual assistants with creative personalities.\n",
      "9. **Translation and Localization**: Use generative AI to:\n",
      "\t* Translate text, audio, and video content into multiple languages.\n",
      "\t* Generate subtitles and closed captions for multimedia content.\n",
      "\t* Optimize website and app content for global markets.\n",
      "10. **Education and Training**: Implement generative AI-powered tools for:\n",
      "\t* Personalized learning experiences and adaptive assessments.\n",
      "\t* Generating educational content, such as videos, quizzes, and interactive lessons.\n",
      "\t* Developing AI-powered tutoring systems and virtual mentors.\n",
      "\n",
      "These business applications of Generative AI can help organizations automate tasks, improve efficiency, and enhance customer experiences. However, it's essential to consider the potential risks and challenges associated with adopting generative AI solutions.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, revolutionizing the way companies operate and interact with their customers. Here are some examples:\n",
      "\n",
      "1. **Customer Service Chatbots**: Generative AI-powered chatbots can understand customer inquiries, respond accordingly, and even generate personalized greeting messages to improve the overall customer experience.\n",
      "2. **Content Generation**: Businesses can use generative AI to create high-quality content, such as articles, social media posts, product descriptions, and marketing materials, saving time and improving consistency.\n",
      "3. **Personalized Marketing**: Generative AI algorithms can analyze customer behavior, preferences, and demographics to predict their needs and generate personalized marketing campaigns, increasing conversion rates and retention.\n",
      "4. **Product Design**: Generative AI can assist in designing innovative products by generating 3D models, product prototypes, and blueprints, reducing design time and costs.\n",
      "5. **Text Summarization**: Generative AI-powered text summarization tools can condense lengthy documents into concise summaries, making it easier for employees to access essential information and stay on top of their work.\n",
      "6. **Automated Transcription**: Generative AI can transcribe audio and video recordings with unprecedented accuracy, reducing the need for manual transcription and enhancing productivity in industries like podcasting, media, and education.\n",
      "7. **Creative Writing**: Collaborative generative writing tools can engage writers to create content on a given topic or theme, freeing up human writers' time and expanding their creative capabilities.\n",
      "8. **Financial Forecasting**: Generative AI models can analyze financial data, identify patterns, and predict future market trends, helping companies make informed decisions and minimize risks.\n",
      "9. **Supply Chain Optimization**: Generative AI algorithms can help optimize supply chain logistics by identifying potential bottlenecks, predicting demand fluctuations, and recommending strategies to improve efficiency.\n",
      "10. **Language Translation**: Generative AI-powered translation tools can facilitate international communication by translating languages, cultures, and nuances for businesses operating globally.\n",
      "11. **Image Editing**: Generative AI's image editing capabilities enable users to create personalized edits, manipulate images, and experiment with new styles without requiring extensive technical expertise.\n",
      "12. **Chatbot Dialogue Management**: Companies can train and develop complex chatbots using generative AI that manage dialogues in real-time based on natural conversation patterns.\n",
      "\n",
      "These applications illustrate the vast potential of Generative AI in transforming business operations and enhancing customer experiences across various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    # response = openai.chat.completions.create(\n",
    "    #     model = \"gpt-4o-mini\",\n",
    "    #     messages = messages_for(website)\n",
    "    # )\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_for(website)\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cff43fe-8acc-4930-b2e4-e630d74d72cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ecco l'elenco dei contenuti della rivista \"La Stampa\" per la pubblicazione del venerdì, con gli articoli principali e i titoli più interessanti:\n",
       "\n",
       "1. **Il Venerdì**: articoli sulla politica italiana, economia e cronaca.\n",
       "2. **Robinson**: articoli di carattere generale sulla società e il mondo.\n",
       "3. **Gedi News Network**: notizie inerenti agli eventi del giorno e alla politica internazionale.\n",
       "\n",
       "Tra i titoli più interessanti degli articoli pubblicati:\n",
       "\n",
       "* \"Il Venerdì, La Stampa analizza il futuro dell'industria\": articolo che esamina le tendenze della settimana e i concetti di interesse come la sostenibilità e l'impresa di tomorrow.\n",
       "* \"Gedi News Network, la politica internazionale: Biden e Putin si incontrano\". Notizia che riporta l'incontro tra il Presidente degli Stati Uniti Joe Biden e il Presidente della Russia Vladimir Putin.\n",
       "* \"Robinson, le storie più interessanti della settimana\": articolo che riporta le notizie più impattanti del mese scorso.\n",
       "* \"Annunci di Formule Passion\" un elenco di annunci dei titolari delle piazze e dei leader dei vari sport.\n",
       "\n",
       "I contenuti si concentrano su argomenti come la politica internazionale, l'economia, la società e la cultura. La revista tenta di offrire una visione d'insieme sulla realtà dell'Italia e del mondo, analizzando gli eventi più significativi della settimana e offerendo articoli di carattere generale."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary('https://www.repubblica.it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ecc8e-a524-4115-aae0-21e9ae462937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
